# Axnmihn

<details open>
<summary><strong>English</strong></summary>

**AI Assistant Backend System**

A modern FastAPI-based AI backend service featuring a 6-layer memory system, MCP ecosystem, and multi-LLM provider integration.

**Tech Stack:** Python 3.12 / FastAPI / PostgreSQL 17 + pgvector / Redis / C++17 Native Module

**License:** MIT

---

## Key Features

- **6-Layer Memory System** â€” M0(Event Buffer) â†’ M1(Working Memory) â†’ M3(Session Archive) â†’ M4(Long-Term) â†’ M5.1-5.3(MemGPT/GraphRAG/MetaMemory)
- **Multi-LLM Support** â€” Gemini, Claude, Circuit Breaker & Fallback
- **MCP Ecosystem** â€” Memory, File, System, Research, Home Assistant integration
- **SIMD Optimization** â€” C++17 native module (memory decay, vector ops, graph traversal)
- **Voice Pipeline** â€” Deepgram Nova-3 (STT) + Qwen3-TTS / OpenAI TTS
- **OpenAI-Compatible API** â€” `/v1/chat/completions` endpoint
- **Adaptive Persona** â€” Channel-specific AI personality adjustment
- **Context Optimization** â€” Token-budget-based smart context assembly
- **Channel Adapters** â€” Discord/Telegram bot integration (streaming message editing, inline commands)

---

## Architecture

### System Overview

```mermaid
graph TB
    subgraph Clients["ğŸ–¥ï¸ Clients"]
        CLI["axel-chat / CLI"]
        WebUI["Open WebUI"]
        Discord["Discord Bot"]
        Telegram["Telegram Bot"]
    end

    subgraph Backend["âš™ï¸ AXNMIHN Backend (FastAPI :8000)"]
        subgraph Ingress["Ingress Layer"]
            API["API Routers<br/>(REST/SSE/WebSocket)"]
            ChannelMgr["Channel Manager<br/>(Adapter Lifecycle)"]
        end

        subgraph Core["Core Services"]
            ChatHandler["ChatHandler<br/>(Orchestrator)"]
            Context["ContextService<br/>(Budget-aware)"]
            ReAct["ReActLoopService<br/>(â‰¤15 iterations)"]
            Search["SearchService<br/>(Tavily)"]
            ToolExec["ToolExecutionService"]
            MemPersist["MemoryPersistenceService"]
            Emotion["EmotionService"]
        end

        subgraph LLM[]
            Claude["Anthropic<br/>Claude Sonnet 4.5<br/>"]
            Gemini["Google<br/>Gemini 3 Flash<br/>"]
        end

        subgraph Memory["6-Layer Memory System"]
            M0["M0: Event Buffer"]
            M1["M1: Working Memory<br/>(20 turns, JSON)"]
            M3["M3: Session Archive<br/>(PostgreSQL/SQLite)"]
            M4["M4: Long-Term<br/>(ChromaDB/pgvector)"]
            M51["M5.1: MemGPT<br/>(budget selection)"]
            M52["M5.2: GraphRAG<br/>(knowledge graph)"]
            M53["M5.3: MetaMemory<br/>(access patterns)"]
        end

        subgraph MCP["MCP Server (:8555)"]
            MCPTools["Tool Registry<br/>(32 tools)"]
        end

        subgraph Media["Media Pipeline"]
            TTS["TTS<br/>(Qwen3 / OpenAI)"]
            STT["STT<br/>(Deepgram Nova-3)"]
        end
    end

    subgraph External["ğŸ”Œ External Services"]
        HASS["Home Assistant<br/>(WiZ/IoT)"]
        Playwright["Playwright<br/>(Browser)"]
        TavilyAPI["Tavily API"]
        DDGAPI["DuckDuckGo API"]
        PG["PostgreSQL"]
        Redis["Redis"]
    end

    CLI & WebUI -->|"OpenAI-compat API"| API
    Discord & Telegram -->|"Channel Adapter Protocol"| ChannelMgr
    ChannelMgr --> ChatHandler
    API --> ChatHandler

    ChatHandler --> Context
    ChatHandler --> ReAct
    ChatHandler --> Search
    ChatHandler --> ToolExec
    ChatHandler --> MemPersist
    ChatHandler --> Emotion

    Context --> Memory
    ReAct --> LLM
    ToolExec --> MCP
    MemPersist --> Memory
    ChatHandler --> Media

    MCPTools --> HASS
    MCPTools --> Playwright
    Search --> TavilyAPI
    Search --> DDGAPI

    M3 & M4 & M52 --> PG
    M0 --> M1 --> M3 -->|"consolidation (6h)"| M4
    M1 -->|"auto-promote"| M4
    M4 --> M51 & M52 & M53
    M52 -->|"feedback"| M4
    M53 -->|"hot boost"| M4
```

### Request Flow

```mermaid
sequenceDiagram
    participant C as Client / Channel Bot
    participant A as API / ChannelManager
    participant CH as ChatHandler
    participant CS as ContextService
    participant MM as MemoryManager
    participant RL as ReActLoop
    participant LLM as LLM Router
    participant MCP as MCP Tools

    C->>A: Message (REST/WebSocket/Bot)
    A->>CH: ChatRequest
    CH->>CS: build_smart_context()
    CS->>MM: parallel fetch (M0+M1+M3+M4+M5)
    MM-->>CS: budgeted context
    CS-->>CH: assembled context

    loop ReAct Loop (â‰¤15)
        CH->>RL: reason + act
        RL->>LLM: generate (Claude/Gemini)
        LLM-->>RL: response + tool_calls
        opt Tool Calls
            RL->>MCP: execute tools
            MCP-->>RL: tool results
        end
    end

    CH->>MM: persist (working + session + long-term)
    MM->>LLM: evaluate importance (facts/insights)
    LLM-->>MM: importance scores
    opt importance â‰¥ 0.6
        MM->>MM: auto-promote to M4
    end
    CH-->>A: streaming response (SSE)
    A-->>C: chunked response
```

### Core Components

| Component | Technology | Purpose |
|-----------|-----------|---------|
| API Server | FastAPI + Uvicorn | Async HTTP/SSE, OpenAI-compatible |
| LLM Router | Gemini 3 Flash + Claude Sonnet 4.5 | Multi-provider, circuit breaker |
| Memory System | 6-layer architecture | Persistent context across sessions |
| MCP Server | Model Context Protocol (SSE) | Tool ecosystem |
| Native Module | C++17 + pybind11 | SIMD-optimized graph/decay ops |
| Audio | Deepgram Nova-3 (STT) + Qwen3-TTS / OpenAI (TTS) | Voice pipeline |
| Home Assistant | REST API | IoT device control |
| Channel Adapters | discord.py + python-telegram-bot | Discord/Telegram bot integration |
| Research | Playwright + Tavily + DuckDuckGo | Web research |

---

## 6-Layer Memory System

The memory system consists of 6 functional layers (M0, M1, M3, M4, M5.1-5.3) orchestrated by `MemoryManager` (`backend/memory/unified/`).

```mermaid
graph TB
    Input["User Message"] --> M0

    subgraph Memory["6-Layer Memory System"]
        M0["M0: Event Buffer<br/><i>real-time event stream</i>"]
        M1["M1: Working Memory<br/><i>in-memory deque (20 turns)</i><br/><i>JSON persistence</i>"]
        M3["M3: Session Archive<br/><i>SQLite / PostgreSQL</i><br/><i>sessions, messages, logs</i>"]
        M4["M4: Long-Term Memory<br/><i>ChromaDB / pgvector</i><br/><i>3072-dim Gemini embeddings</i><br/><i>adaptive decay, dedup</i>"]

        M51["M5.1: MemGPT<br/><i>budget-aware selection</i><br/><i>token-budgeted assembly</i>"]
        M52["M5.2: GraphRAG<br/><i>entity-relation graph</i><br/><i>spaCy NER + LLM extraction</i><br/><i>BFS traversal (C++ for 100+)</i>"]
        M53["M5.3: MetaMemory<br/><i>access pattern tracking</i><br/><i>hot memory detection</i>"]
    end

    M0 --> M1
    M1 -->|"immediate persist"| M3
    M1 -->|"auto-promote<br/>(importance â‰¥ 0.6)"| M4
    M3 -->|"consolidation (6h)<br/>+ reassessment"| M4
    M4 --> M51
    M4 --> M52
    M4 --> M53
    M52 -->|"connection_count<br/>feedback"| M4
    M53 -->|"hot boost"| M4

    Context["ContextService<br/>build_smart_context()"] -.->|"parallel fetch"| M0 & M1 & M3 & M4 & M51 & M52 & M53
```

### Layer Details

| Layer | File | Storage | Purpose |
|-------|------|---------|---------|
| M0 Event Buffer | `memory/event_buffer.py` | In-memory | Real-time event streaming |
| M1 Working Memory | `memory/current.py` | `data/working_memory.json` | Current conversation buffer (20 turns) |
| M3 Session Archive | `memory/recent/` | `data/sqlite/sqlite_memory.db` | Session summaries, message history |
| M4 Long-Term Memory | `memory/permanent/` | `data/chroma_db/` | Semantic vector search, importance decay |
| M5.1 MemGPT | `memory/memgpt.py` | In-memory | Token-budget selection, topic diversity |
| M5.2 GraphRAG | `memory/graph_rag/` | `data/knowledge_graph.json` | Entity/relation graph, BFS traversal |
| M5.3 MetaMemory | `memory/meta_memory.py` | SQLite | Access frequency, channel diversity |

### Memory Decay

Memories decay over time using an adaptive forgetting curve:

```
decayed_importance = importance * decay_factor

decay_factor = f(
    time_elapsed,           # exponential time decay
    base_rate=0.001,        # configurable via MEMORY_BASE_DECAY_RATE
    access_count,           # repeated access slows decay
    connection_count,       # graph-connected memories resist decay
    memory_type_modifier,   # facts decay slower than conversations
    circadian_stability     # peak-hour boost via apply_circadian_stability()
)

deletion threshold: 0.03   (MEMORY_DECAY_DELETE_THRESHOLD)
min retention: 0.3         (MEMORY_MIN_RETENTION)
similarity dedup: 0.90     (MEMORY_SIMILARITY_THRESHOLD)
```

### Retrieval Scoring

Long-term memory retrieval applies a multi-factor scoring pipeline:

```
effective_score = base_relevance * decay_factor * importance_weight

importance_weight = 0.5 + 0.5 * clamp(importance, 0, 1)   # range: [0.5, 1.0]
```

- **M5 Hot Memory Boost**: Memories flagged as "hot" by MetaMemory receive a score bonus (+0.1)
- **GraphRAG LLM Relevance**: Async queries use LLM-evaluated relevance instead of simple entity-count heuristics

### Context Assembly

`await MemoryManager.build_smart_context()` assembles context from all layers via async parallel fetch (sync wrapper: `build_smart_context_sync()`):

| Section | Default Budget (chars) | Config Key |
|---------|----------------------|------------|
| System Prompt | 20,000 | `BUDGET_SYSTEM_PROMPT` |
| Temporal Context | 5,000 | `BUDGET_TEMPORAL` |
| Working Memory | 80,000 | `BUDGET_WORKING_MEMORY` |
| Long-Term Memory | 30,000 | `BUDGET_LONG_TERM` |
| GraphRAG | 12,000 | `BUDGET_GRAPHRAG` |
| Session Archive | 8,000 | `BUDGET_SESSION_ARCHIVE` |

`ContextService` also fetches M0 (Event Buffer) and M5 (Hot Memories) sections for complete 6-layer coverage.

### Session Management

- **Auto session timeout**: Sessions automatically end after 30 minutes of inactivity
- **Shutdown LLM summary**: On app shutdown, attempts LLM-based session summary (10s timeout, fallback on failure)
- **LLM importance evaluation**: Facts and insights are scored by LLM at session end (fallback: 0.5)
- **Auto-promotion (M2â†’M3)**: Sessions with LLM importance â‰¥ 0.6 are automatically promoted to long-term as `conversation` type
- **Memory promotion criteria**: importance â‰¥ 0.55, or (repetitions â‰¥ 2 AND importance â‰¥ 0.35)

### Auto Consolidation

The app runs `consolidate_memories()` automatically every 6 hours. Additionally, `scripts/memory_gc.py` can be registered as a cron job for hash/semantic deduplication.

- **User behavior metrics**: Consolidator collects real user behavior metrics via `collect_behavior_metrics()` for adaptive decay
- **Importance reassessment**: Old memories (>168h) with high access counts are periodically re-evaluated by LLM (batch size: 50)
- **GraphRAG â†’ M3 feedback**: Entity extraction updates `connection_count` on related long-term memories

### PostgreSQL Backend (Optional)

When `DATABASE_URL` is set, the system uses PostgreSQL + pgvector instead of SQLite/ChromaDB:

```
backend/memory/pg/
  connection.py            # PgConnectionManager (connection pool)
  memory_repository.py     # PgMemoryRepository (replaces ChromaDB)
  graph_repository.py      # PgGraphRepository (replaces JSON graph)
  session_repository.py    # PgSessionRepository (replaces SQLite)
  meta_repository.py       # PgMetaMemoryRepository
  interaction_logger.py    # PgInteractionLogger
```

Requires: `pgvector/pgvector:pg17` (see `docker-compose.yml`)

---

## API Endpoints

All endpoints require `Authorization: Bearer <token>` or `X-API-Key` header authentication (except health/status endpoints).

### Health & Status

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/health` | GET | Full health check (memory, LLM, modules) |
| `/health/quick` | GET | Minimal liveness check |
| `/metrics` | GET | Prometheus metrics (text format) |
| `/auth/status` | GET | Auth status |
| `/llm/providers` | GET | Available LLM providers |
| `/models` | GET | Available models |

### Chat (OpenAI-Compatible)

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/v1/chat/completions` | POST | Chat completion (streaming/non-streaming) |
| `/v1/models` | GET | Available models list |

### WebSocket

| Endpoint | Protocol | Description |
|----------|----------|-------------|
| `/ws` | WebSocket | Real-time chat (auth, rate limiting 30msg/min, heartbeat) |

### Memory

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/memory/consolidate` | POST | Trigger decay + persona evolution |
| `/memory/stats` | GET | Memory layer statistics |
| `/memory/search?query=&limit=` | GET | Semantic memory search |
| `/memory/sessions` | GET | Recent session summaries |
| `/memory/session/{session_id}` | GET | Session detail |
| `/memory/interaction-logs` | GET | Interaction logs |
| `/memory/interaction-stats` | GET | Interaction statistics |
| `/session/end` | POST | End current session |

### Audio

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/v1/audio/transcriptions` | POST | STT (Deepgram Nova-3) |
| `/v1/audio/speech` | POST | TTS synthesis |
| `/v1/audio/voices` | GET | Available TTS voices |
| `/transcribe` | POST | Audio file transcription |
| `/upload` | POST | File upload |

### MCP

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/mcp/status` | GET | MCP server status |
| `/mcp/manifest` | GET | MCP tool manifest |
| `/mcp/execute` | POST | Execute MCP tool |

### Code Browsing

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/code/summary` | GET | Codebase summary |
| `/code/files` | GET | Code file listing |

---

## MCP Ecosystem

32 tools served via SSE transport. Categories:

- **System (9):** run_command, search_codebase, search_codebase_regex, read_system_logs, list_available_logs, analyze_log_errors, check_task_status, tool_metrics, system_status
- **Memory (6):** query_axel_memory, add_memory, store_memory, retrieve_context, get_recent_logs, memory_stats
- **File (3):** read_file, list_directory, get_source_code
- **Research (6):** web_search, visit_webpage, deep_research, tavily_search, read_artifact, list_artifacts
- **Home Assistant (6):** hass_control_light, hass_control_device, hass_read_sensor, hass_get_state, hass_list_entities, hass_execute_scene
- **Delegation (2):** delegate_to_opus, google_deep_research

Tool visibility is configurable via `MCP_DISABLED_TOOLS` and `MCP_DISABLED_CATEGORIES` env vars.

---

## Native C++ Module

Performance-critical operations via C++17 + pybind11 + SIMD (AVX2/NEON):

```
backend/native/src/
  axnmihn_native.cpp      # pybind11 bindings
  decay.cpp/.hpp           # Memory decay (SIMD batch)
  vector_ops.cpp/.hpp      # Cosine similarity, duplicate detection
  string_ops.cpp/.hpp      # Levenshtein distance
  graph_ops.cpp/.hpp       # BFS traversal
  text_ops.cpp/.hpp        # Text processing
```

All call sites fall back to pure Python if the module is not installed.

```bash
cd backend/native && pip install .
# Requires: CMake 3.18+, C++17 compiler, pybind11
```

---

## Configuration

### Environment Variables (`.env`)

```bash
# API Keys
GEMINI_API_KEY=your-gemini-api-key
ANTHROPIC_API_KEY=your-anthropic-api-key
OPENAI_API_KEY=your-openai-api-key
TAVILY_API_KEY=your-tavily-api-key
DEEPGRAM_API_KEY=your-deepgram-api-key

# Home Assistant
HASS_URL=http://homeassistant.local:8123
HASS_TOKEN=your-hass-long-lived-token

# Server
AXNMIHN_API_KEY=your-api-key
HOST=0.0.0.0
PORT=8000
DEBUG=false
TZ=America/Vancouver

# Models
CHAT_PROVIDER=google
GEMINI_MODEL=gemini-3-flash-preview
ANTHROPIC_MODEL=claude-sonnet-4-5-20250929
ANTHROPIC_THINKING_BUDGET=10000
EMBEDDING_MODEL=models/gemini-embedding-001
EMBEDDING_DIMENSION=3072

# Memory budgets (chars)
BUDGET_SYSTEM_PROMPT=20000
BUDGET_TEMPORAL=5000
BUDGET_WORKING_MEMORY=80000
BUDGET_LONG_TERM=30000
BUDGET_GRAPHRAG=12000
BUDGET_SESSION_ARCHIVE=8000

# Memory decay
MEMORY_BASE_DECAY_RATE=0.001
MEMORY_MIN_RETENTION=0.3
MEMORY_DECAY_DELETE_THRESHOLD=0.03
MEMORY_SIMILARITY_THRESHOLD=0.90
MEMORY_MIN_IMPORTANCE=0.55

# Context
CONTEXT_WORKING_TURNS=20
CONTEXT_FULL_TURNS=6
CONTEXT_MAX_CHARS=500000

# Providers
DEFAULT_LLM_PROVIDER=gemini
SEARCH_PROVIDER=tavily

# PostgreSQL
DATABASE_URL=postgresql://axel:password@localhost:5432/axel
PG_POOL_MIN=2
PG_POOL_MAX=10

# Docker Compose (docker-compose.ymlì—ì„œ ì‚¬ìš©, ì„ íƒ)
# POSTGRES_USER=axel
# POSTGRES_PASSWORD=change-me-in-production
# POSTGRES_DB=axel

# TTS Configuration
TTS_SERVICE_URL=http://127.0.0.1:8002
TTS_SYNTHESIS_TIMEOUT=30.0
TTS_FFMPEG_TIMEOUT=10.0
TTS_QUEUE_MAX_PENDING=3
TTS_IDLE_TIMEOUT=300

# Channel Adapters (Discord / Telegram)
DISCORD_BOT_TOKEN=
DISCORD_ALLOWED_CHANNELS=           # comma-separated channel IDs (optional)
TELEGRAM_BOT_TOKEN=
TELEGRAM_ALLOWED_USERS=             # comma-separated usernames (optional)
TELEGRAM_ALLOWED_CHATS=             # comma-separated chat IDs (optional)

# Admin
AXNMIHN_ADMIN_EMAIL=admin@example.com
```

---

## Quick Start

### Option A: Docker (Recommended)

```bash
git clone https://github.com/NorthProt-Inc/axnmihn.git
cd axnmihn

cp .env.example .env
# Edit .env with API keys

docker compose up -d

# Verify
curl http://localhost:8000/health/quick
```

This starts: backend (8000) + MCP (8555) + research (8766) + PostgreSQL (5432) + Redis (6379).

### Option B: Local Development

```bash
git clone https://github.com/NorthProt-Inc/axnmihn.git
cd axnmihn

python3.12 -m venv venv
source venv/bin/activate
pip install -r backend/requirements.txt

cp .env.example .env
# Edit .env with API keys

# (Optional) Native C++ module
cd backend/native && pip install . && cd ../..

# (Optional) Playwright for research
playwright install chromium

# (Optional) PostgreSQL + Redis
docker compose up -d postgres redis

# Run
uvicorn backend.app:app --host 0.0.0.0 --port 8000
curl http://localhost:8000/health
```

---

## Deployment

### Docker Compose (Full Stack)

```bash
docker compose up -d              # Start all services
docker compose ps                 # Status
docker compose logs backend -f    # Follow backend logs
docker compose down               # Stop all
```

| Service | Port | Image/Target | Resources |
|---------|------|-------------|-----------|
| `backend` | 8000 | Dockerfile â†’ runtime | 4G RAM, 2 CPU |
| `mcp` | 8555 | Dockerfile â†’ runtime | 1G RAM, 1 CPU |
| `research` | 8766 | Dockerfile â†’ research | 2G RAM, 1.5 CPU |

Infrastructure (PostgreSQL, Redis) runs as native systemd services. TTS (GPU-dependent) is commented out in docker-compose.yml. Uncomment if NVIDIA GPU is available.

### Systemd Services (Bare Metal)

| Service | Port | Purpose | Resources |
|---------|------|---------|-----------|
| `axnmihn-backend` | 8000 | FastAPI backend | 4G RAM, 200% CPU |
| `axnmihn-mcp` | 8555 | MCP server (SSE) | 1G RAM, 100% CPU |
| `axnmihn-research` | 8766 | Research MCP | 2G RAM, 150% CPU |
| `axnmihn-tts` | 8002 | TTS microservice (Qwen3-TTS) | 4G RAM, 200% CPU |
| `axnmihn-wakeword` | - | Wakeword detection | 512M RAM, 50% CPU |
| `context7-mcp` | 3002 | Context7 MCP | 1G RAM |
| `markitdown-mcp` | 3001 | Markitdown MCP | 1G RAM |

See [OPERATIONS.md](OPERATIONS.md) for detailed operations guide.

### Maintenance

| Script | Purpose |
|--------|---------|
| `scripts/memory_gc.py` | Memory garbage collection (dedup, decay, oversized removal) |
| `scripts/db_maintenance.py` | SQLite VACUUM, ANALYZE, integrity check |
| `scripts/dedup_knowledge_graph.py` | Knowledge graph deduplication |
| `scripts/regenerate_persona.py` | 7-day incremental persona update |
| `scripts/optimize_memory.py` | 4-phase memory optimization (text cleaning, role normalization) |
| `scripts/cleanup_messages.py` | LLM-powered message cleanup (parallel, checkpointed) |
| `scripts/populate_knowledge_graph.py` | Knowledge graph initial population |
| `scripts/night_ops.py` | Automated night shift research |
| `scripts/run_migrations.py` | Database schema migrations |

---

## Project Structure

```
axnmihn/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app.py                    # FastAPI entry point, lifespan
â”‚   â”œâ”€â”€ config.py                 # All configuration
â”‚   â”œâ”€â”€ api/                      # HTTP routers (status, chat, memory, mcp, media, audio, openai)
â”‚   â”œâ”€â”€ core/                     # Core services
â”‚   â”‚   â”œâ”€â”€ chat_handler.py       # Message routing
â”‚   â”‚   â”œâ”€â”€ context_optimizer.py  # Context size management
â”‚   â”‚   â”œâ”€â”€ mcp_client.py        # MCP client
â”‚   â”‚   â”œâ”€â”€ mcp_server.py        # MCP server setup
â”‚   â”‚   â”œâ”€â”€ health/              # Health monitoring
â”‚   â”‚   â”œâ”€â”€ identity/            # AI persona (ai_brain.py)
â”‚   â”‚   â”œâ”€â”€ intent/              # Intent classification
â”‚   â”‚   â”œâ”€â”€ logging/             # Structured logging
â”‚   â”‚   â”œâ”€â”€ mcp_tools/           # Tool implementations
â”‚   â”‚   â”œâ”€â”€ persona/             # Channel adaptation
â”‚   â”‚   â”œâ”€â”€ security/            # Prompt defense
â”‚   â”‚   â”œâ”€â”€ session/             # Session state
â”‚   â”‚   â”œâ”€â”€ telemetry/           # Interaction logging
â”‚   â”‚   â””â”€â”€ utils/               # Cache, retry, HTTP pool, Gemini client, circuit breaker
â”‚   â”œâ”€â”€ llm/                     # LLM providers (Gemini, Anthropic)
â”‚   â”œâ”€â”€ media/                   # TTS manager
â”‚   â”œâ”€â”€ memory/                  # 6-layer memory system
â”‚   â”‚   â”œâ”€â”€ unified/             # MemoryManager orchestrator (core, facade, context_builder, session)
â”‚   â”‚   â”œâ”€â”€ event_buffer.py      # M0: Event buffer
â”‚   â”‚   â”œâ”€â”€ current.py           # M1: Working memory
â”‚   â”‚   â”œâ”€â”€ recent/              # M3: Session archive (SQLite)
â”‚   â”‚   â”œâ”€â”€ permanent/           # M4: Long-term (ChromaDB)
â”‚   â”‚   â”œâ”€â”€ memgpt.py            # M5.1: Budget selection
â”‚   â”‚   â”œâ”€â”€ graph_rag/           # M5.2: Knowledge graph
â”‚   â”‚   â”œâ”€â”€ meta_memory.py       # M5.3: Access tracking
â”‚   â”‚   â”œâ”€â”€ temporal.py          # Time context
â”‚   â”‚   â””â”€â”€ pg/                  # PostgreSQL backend (optional)
â”‚   â”œâ”€â”€ native/                  # C++17 extension module
â”‚   â”œâ”€â”€ channels/                # Channel adapter system
â”‚   â”‚   â”œâ”€â”€ protocol.py          # ChannelAdapter Protocol
â”‚   â”‚   â”œâ”€â”€ manager.py           # Lifecycle management
â”‚   â”‚   â”œâ”€â”€ message_chunker.py   # Platform message splitting
â”‚   â”‚   â”œâ”€â”€ bridge.py            # ChatHandler bridge
â”‚   â”‚   â”œâ”€â”€ discord/bot.py       # Discord adapter
â”‚   â”‚   â”œâ”€â”€ telegram/bot.py      # Telegram adapter
â”‚   â”‚   â””â”€â”€ commands/registry.py # Inline command parser
â”‚   â”œâ”€â”€ protocols/mcp/           # MCP protocol handlers
â”‚   â””â”€â”€ wake/                    # Wakeword + voice conversation
â”œâ”€â”€ tests/                       # pytest suite
â”œâ”€â”€ scripts/                     # Automation scripts
â”œâ”€â”€ data/                        # Runtime data (SQLite, ChromaDB, JSON)
â”œâ”€â”€ logs/                        # Application logs
â”œâ”€â”€ storage/                     # Research artifacts, cron reports
â”œâ”€â”€ Dockerfile                   # Multi-stage (runtime + research)
â”œâ”€â”€ docker-compose.yml           # Full stack (app + PG + Redis)
â”œâ”€â”€ .dockerignore
â”œâ”€â”€ pyproject.toml               # Project metadata
â””â”€â”€ .env                         # Environment configuration
```

---

## Documentation

- [OPERATIONS.md](OPERATIONS.md) â€” Operations guide (KR/EN)
- [AGENTS.md](AGENTS.md) â€” Custom agent definitions
- [logging.md](logging.md) â€” Logging system documentation
- [memory-system-analysis.md](memory-system-analysis.md) â€” Memory system analysis report
- [backend/native/README.md](backend/native/README.md) â€” C++ native module
- `.github/instructions/` â€” Development guidelines (TDD, security, performance, error analysis)

---

## Contributing

1. Fork the repository
2. Create feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'feat: add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open Pull Request

**Commit Convention:** Conventional Commits (`feat:`, `fix:`, `docs:`, `refactor:`, etc.)

**Code Style:**
- Python: `black` formatting, `ruff` linting, type hints required
- Max 400 lines per function, 800 lines per file
- Protocol-based interfaces, dataclass/pydantic data
- Prefer async def (I/O-bound operations)

---

## License

MIT License - see [LICENSE](LICENSE) for details

---

## Acknowledgments

- **FastAPI** â€” Modern web framework
- **ChromaDB** â€” Vector database
- **Anthropic & Google** â€” LLM APIs
- **Deepgram** â€” Speech recognition
- **Model Context Protocol** â€” Tool integration standard

---

**Made by:** NorthProt Inc.  
**Contact:** [GitHub Issues](https://github.com/NorthProt-Inc/axnmihn/issues)

</details>


---

<details>
<summary><strong>í•œêµ­ì–´</strong></summary>

**AI ì–´ì‹œìŠ¤í„´íŠ¸ ë°±ì—”ë“œ ì‹œìŠ¤í…œ**

FastAPI ê¸°ë°˜ì˜ AI ë°±ì—”ë“œ ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤. 6ê³„ì¸µ ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ, MCP ìƒíƒœê³„, ë©€í‹° LLM í”„ë¡œë°”ì´ë”ë¥¼ í†µí•©í•œ í˜„ëŒ€ì ì¸ ì•„í‚¤í…ì²˜ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

**ê¸°ìˆ  ìŠ¤íƒ:** Python 3.12 / FastAPI / PostgreSQL 17 + pgvector / Redis / C++17 ë„¤ì´í‹°ë¸Œ ëª¨ë“ˆ

**ë¼ì´ì„ ìŠ¤:** MIT

---

## ì£¼ìš” ê¸°ëŠ¥

- **6ê³„ì¸µ ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ** â€” M0(ì´ë²¤íŠ¸ ë²„í¼) â†’ M1(ì›Œí‚¹ ë©”ëª¨ë¦¬) â†’ M3(ì„¸ì…˜ ì•„ì¹´ì´ë¸Œ) â†’ M4(ì¥ê¸° ë©”ëª¨ë¦¬) â†’ M5.1-5.3(MemGPT/GraphRAG/MetaMemory)
- **ë©€í‹° LLM ì§€ì›** â€” Gemini 3 Flash, Claude Sonnet 4.5, Circuit Breaker & Fallback
- **MCP ìƒíƒœê³„** â€” ë©”ëª¨ë¦¬, íŒŒì¼, ì‹œìŠ¤í…œ, ë¦¬ì„œì¹˜, Home Assistant í†µí•©
- **SIMD ìµœì í™”** â€” C++17 ë„¤ì´í‹°ë¸Œ ëª¨ë“ˆ (ë©”ëª¨ë¦¬ decay, ë²¡í„° ì—°ì‚°, ê·¸ë˜í”„ íƒìƒ‰)
- **ìŒì„± íŒŒì´í”„ë¼ì¸** â€” Deepgram Nova-3 (STT) + Qwen3-TTS / OpenAI TTS
- **OpenAI í˜¸í™˜ API** â€” `/v1/chat/completions` ì—”ë“œí¬ì¸íŠ¸
- **ì ì‘í˜• í˜ë¥´ì†Œë‚˜** â€” ì±„ë„ë³„ AI ì„±ê²© ìë™ ì¡°ì •
- **ì»¨í…ìŠ¤íŠ¸ ìµœì í™”** â€” í† í° ì˜ˆì‚° ê¸°ë°˜ ìŠ¤ë§ˆíŠ¸ ì»¨í…ìŠ¤íŠ¸ ì¡°ë¦½
- **WebSocket ì‹¤ì‹œê°„ í†µì‹ ** â€” ì¸ì¦, Rate Limiting, Heartbeat ì§€ì› (`/ws`)
- **Prometheus ë©”íŠ¸ë¦­ìŠ¤** â€” `GET /metrics` ì—”ë“œí¬ì¸íŠ¸ (Counter, Gauge, Histogram)
- **êµ¬ì¡°í™”ëœ ì—ëŸ¬ ê³„ì¸µ** â€” `AxnmihnError` ê¸°ë°˜ 7ê³„ì¸µ ì—ëŸ¬ ë¶„ë¥˜ (ìë™ HTTP ìƒíƒœ ë§¤í•‘)
- **Intent ë¶„ë¥˜ê¸°** â€” í‚¤ì›Œë“œ ê¸°ë°˜ 6ì¢… ì¸í…íŠ¸ ë¶„ë¥˜ (chat, search, tool_use, memory_query, command, creative)
- **ì»´í¬ë„ŒíŠ¸ í—¬ìŠ¤ì²´í¬** â€” Memory, LLM, PostgreSQL ë…ë¦½ í—¬ìŠ¤ì²´í¬ + latency ì¶”ì 
- **ì±„ë„ ì–´ëŒ‘í„°** â€” Discord/Telegram ë´‡ í†µí•© (ìŠ¤íŠ¸ë¦¬ë° ë©”ì‹œì§€ í¸ì§‘, ì¸ë¼ì¸ ì»¤ë§¨ë“œ)

---

## ì•„í‚¤í…ì²˜

### ì‹œìŠ¤í…œ ê°œìš”

```mermaid
graph TB
    subgraph Clients["ğŸ–¥ï¸ í´ë¼ì´ì–¸íŠ¸"]
        CLI["axel-chat / CLI"]
        WebUI["Open WebUI"]
        Discord["Discord ë´‡"]
        Telegram["Telegram ë´‡"]
    end

    subgraph Backend["âš™ï¸ AXNMIHN ë°±ì—”ë“œ (FastAPI :8000)"]
        subgraph Ingress["ì¸ê·¸ë ˆìŠ¤ ê³„ì¸µ"]
            API["API ë¼ìš°í„°<br/>(REST/SSE/WebSocket)"]
            ChannelMgr["ì±„ë„ ë§¤ë‹ˆì €<br/>(ì–´ëŒ‘í„° ë¼ì´í”„ì‚¬ì´í´)"]
        end

        subgraph Core["í•µì‹¬ ì„œë¹„ìŠ¤"]
            ChatHandler["ChatHandler<br/>(ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°)"]
            Context["ContextService<br/>(ì˜ˆì‚° ê¸°ë°˜)"]
            ReAct["ReActLoopService<br/>(â‰¤15 ë°˜ë³µ)"]
            Search["SearchService<br/>(Tavily)"]
            ToolExec["ToolExecutionService"]
            MemPersist["MemoryPersistenceService"]
            Emotion["EmotionService"]
        end

        subgraph LLM["LLM ë¼ìš°í„° (Circuit Breaker)"]
            Claude["Anthropic<br/>Claude Sonnet 4.5<br/>(ì±„íŒ…)"]
            Gemini["Google<br/>Gemini 3 Flash<br/>(ìœ í‹¸ë¦¬í‹°)"]
        end

        subgraph Memory["6ê³„ì¸µ ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ"]
            M0["M0: ì´ë²¤íŠ¸ ë²„í¼"]
            M1["M1: ì›Œí‚¹ ë©”ëª¨ë¦¬<br/>(20í„´, JSON)"]
            M3["M3: ì„¸ì…˜ ì•„ì¹´ì´ë¸Œ<br/>(PostgreSQL/SQLite)"]
            M4["M4: ì¥ê¸° ë©”ëª¨ë¦¬<br/>(ChromaDB/pgvector)"]
            M51["M5.1: MemGPT<br/>(ì˜ˆì‚° ê¸°ë°˜ ì„ íƒ)"]
            M52["M5.2: GraphRAG<br/>(ì§€ì‹ ê·¸ë˜í”„)"]
            M53["M5.3: MetaMemory<br/>(ì ‘ê·¼ íŒ¨í„´)"]
        end

        subgraph MCP["MCP ì„œë²„ (:8555)"]
            MCPTools["ë„êµ¬ ë ˆì§€ìŠ¤íŠ¸ë¦¬<br/>(32ê°œ ë„êµ¬)"]
        end

        subgraph Media["ë¯¸ë””ì–´ íŒŒì´í”„ë¼ì¸"]
            TTS["TTS<br/>(Qwen3 / OpenAI)"]
            STT["STT<br/>(Deepgram Nova-3)"]
        end
    end

    subgraph External["ğŸ”Œ ì™¸ë¶€ ì„œë¹„ìŠ¤"]
        HASS["Home Assistant<br/>(WiZ/IoT)"]
        Playwright["Playwright<br/>(ë¸Œë¼ìš°ì €)"]
        TavilyAPI["Tavily API"]
        DDGAPI["DuckDuckGo API"]
        PG["PostgreSQL"]
        Redis["Redis"]
    end

    CLI & WebUI -->|"OpenAI í˜¸í™˜ API"| API
    Discord & Telegram -->|"ì±„ë„ ì–´ëŒ‘í„° í”„ë¡œí† ì½œ"| ChannelMgr
    ChannelMgr --> ChatHandler
    API --> ChatHandler

    ChatHandler --> Context
    ChatHandler --> ReAct
    ChatHandler --> Search
    ChatHandler --> ToolExec
    ChatHandler --> MemPersist
    ChatHandler --> Emotion

    Context --> Memory
    ReAct --> LLM
    ToolExec --> MCP
    MemPersist --> Memory
    ChatHandler --> Media

    MCPTools --> HASS
    MCPTools --> Playwright
    Search --> TavilyAPI
    Search --> DDGAPI

    M3 & M4 & M52 --> PG
    M0 --> M1 --> M3 -->|"í†µí•© (6ì‹œê°„)"| M4
    M1 -->|"ìë™ í”„ë¡œëª¨ì…˜"| M4
    M4 --> M51 & M52 & M53
    M52 -->|"í”¼ë“œë°±"| M4
    M53 -->|"í•« ë¶€ìŠ¤íŠ¸"| M4
```

### ìš”ì²­ íë¦„

```mermaid
sequenceDiagram
    participant C as í´ë¼ì´ì–¸íŠ¸ / ì±„ë„ ë´‡
    participant A as API / ChannelManager
    participant CH as ChatHandler
    participant CS as ContextService
    participant MM as MemoryManager
    participant RL as ReActLoop
    participant LLM as LLM ë¼ìš°í„°
    participant MCP as MCP ë„êµ¬

    C->>A: ë©”ì‹œì§€ (REST/WebSocket/ë´‡)
    A->>CH: ChatRequest
    CH->>CS: build_smart_context()
    CS->>MM: ë³‘ë ¬ ì¡°íšŒ (M0+M1+M3+M4+M5)
    MM-->>CS: ì˜ˆì‚° ê¸°ë°˜ ì»¨í…ìŠ¤íŠ¸
    CS-->>CH: ì¡°ë¦½ëœ ì»¨í…ìŠ¤íŠ¸

    loop ReAct ë£¨í”„ (â‰¤15íšŒ)
        CH->>RL: ì¶”ë¡  + ì‹¤í–‰
        RL->>LLM: ìƒì„± (Claude/Gemini)
        LLM-->>RL: ì‘ë‹µ + tool_calls
        opt ë„êµ¬ í˜¸ì¶œ
            RL->>MCP: ë„êµ¬ ì‹¤í–‰
            MCP-->>RL: ë„êµ¬ ê²°ê³¼
        end
    end

    CH->>MM: ì˜ì†í™” (working + session + long-term)
    MM->>LLM: ì¤‘ìš”ë„ í‰ê°€ (facts/insights)
    LLM-->>MM: importance ì ìˆ˜
    opt importance â‰¥ 0.6
        MM->>MM: M4ë¡œ ìë™ í”„ë¡œëª¨ì…˜
    end
    CH-->>A: ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ (SSE)
    A-->>C: ì²­í¬ ì‘ë‹µ
```

### í•µì‹¬ ì»´í¬ë„ŒíŠ¸

| ì»´í¬ë„ŒíŠ¸ | ê¸°ìˆ  | ëª©ì  |
|----------|------|------|
| API ì„œë²„ | FastAPI + Uvicorn | Async HTTP/SSE/WebSocket, OpenAI í˜¸í™˜ |
| LLM ë¼ìš°í„° | Gemini 3 Flash + Claude Sonnet 4.5 | ë©€í‹° í”„ë¡œë°”ì´ë”, Circuit Breaker |
| ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ | 6ê³„ì¸µ ì•„í‚¤í…ì²˜ | ì„¸ì…˜ ê°„ ì§€ì†ì ì¸ ì»¨í…ìŠ¤íŠ¸ |
| MCP ì„œë²„ | Model Context Protocol (SSE) | ë„êµ¬ ìƒíƒœê³„ |
| í…”ë ˆë©”íŠ¸ë¦¬ | Prometheus ë©”íŠ¸ë¦­ìŠ¤ + ì—ëŸ¬ ê³„ì¸µ | ê´€ì¸¡ì„± + êµ¬ì¡°í™”ëœ ì—ëŸ¬ ì²˜ë¦¬ |
| ë„¤ì´í‹°ë¸Œ ëª¨ë“ˆ | C++17 + pybind11 | SIMD ìµœì í™” (ê·¸ë˜í”„/decay) |
| ì˜¤ë””ì˜¤ | Deepgram Nova-3 (STT) + Qwen3-TTS / OpenAI (TTS) | ìŒì„± íŒŒì´í”„ë¼ì¸ |
| ì±„ë„ ì–´ëŒ‘í„° | discord.py + python-telegram-bot | Discord/Telegram ë´‡ í†µí•© |
| Home Assistant | REST API | IoT ë””ë°”ì´ìŠ¤ ì œì–´ |
| ë¦¬ì„œì¹˜ | Playwright + Tavily + DuckDuckGo | ì›¹ ë¦¬ì„œì¹˜ |

---

## 6ê³„ì¸µ ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ

ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œì€ 6ê°œì˜ ê¸°ëŠ¥ ê³„ì¸µ (M0, M1, M3, M4, M5.1-5.3)ìœ¼ë¡œ êµ¬ì„±ë˜ë©° `MemoryManager`(`backend/memory/unified/`)ê°€ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜í•©ë‹ˆë‹¤.

```mermaid
graph TB
    Input["ì‚¬ìš©ì ë©”ì‹œì§€"] --> M0

    subgraph Memory["6ê³„ì¸µ ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ"]
        M0["M0: ì´ë²¤íŠ¸ ë²„í¼<br/><i>ì‹¤ì‹œê°„ ì´ë²¤íŠ¸ ìŠ¤íŠ¸ë¦¼</i>"]
        M1["M1: ì›Œí‚¹ ë©”ëª¨ë¦¬<br/><i>ì¸ë©”ëª¨ë¦¬ deque (20í„´)</i><br/><i>JSON ì˜ì†í™”</i>"]
        M3["M3: ì„¸ì…˜ ì•„ì¹´ì´ë¸Œ<br/><i>SQLite / PostgreSQL</i><br/><i>ì„¸ì…˜, ë©”ì‹œì§€, ë¡œê·¸</i>"]
        M4["M4: ì¥ê¸° ë©”ëª¨ë¦¬<br/><i>ChromaDB / pgvector</i><br/><i>3072ì°¨ì› Gemini ì„ë² ë”©</i><br/><i>ì ì‘í˜• decay, ì¤‘ë³µ ì œê±°</i>"]

        M51["M5.1: MemGPT<br/><i>ì˜ˆì‚° ê¸°ë°˜ ì„ íƒ</i><br/><i>í† í° ì˜ˆì‚° ì¡°ë¦½</i>"]
        M52["M5.2: GraphRAG<br/><i>ì—”í‹°í‹°-ê´€ê³„ ê·¸ë˜í”„</i><br/><i>spaCy NER + LLM ì¶”ì¶œ</i><br/><i>BFS íƒìƒ‰ (100+ ì‹œ C++)</i>"]
        M53["M5.3: MetaMemory<br/><i>ì ‘ê·¼ íŒ¨í„´ ì¶”ì </i><br/><i>í•« ë©”ëª¨ë¦¬ ê°ì§€</i>"]
    end

    M0 --> M1
    M1 -->|"ì¦‰ì‹œ ì˜ì†í™”"| M3
    M1 -->|"ìë™ í”„ë¡œëª¨ì…˜<br/>(importance â‰¥ 0.6)"| M4
    M3 -->|"í†µí•© (6ì‹œê°„)<br/>+ ì¬í‰ê°€"| M4
    M4 --> M51
    M4 --> M52
    M4 --> M53
    M52 -->|"connection_count<br/>í”¼ë“œë°±"| M4
    M53 -->|"í•« ë¶€ìŠ¤íŠ¸"| M4

    Context["ContextService<br/>build_smart_context()"] -.->|"ë³‘ë ¬ ì¡°íšŒ"| M0 & M1 & M3 & M4 & M51 & M52 & M53
```

### ê³„ì¸µ ìƒì„¸

| ê³„ì¸µ | íŒŒì¼ | ì €ì¥ì†Œ | ëª©ì  |
|------|------|--------|------|
| M0 Event Buffer | `memory/event_buffer.py` | ì¸ë©”ëª¨ë¦¬ | ì‹¤ì‹œê°„ ì´ë²¤íŠ¸ ìŠ¤íŠ¸ë¦¬ë° |
| M1 Working Memory | `memory/current.py` | `data/working_memory.json` | í˜„ì¬ ëŒ€í™” ë²„í¼ (20í„´) |
| M3 Session Archive | `memory/recent/` | `data/sqlite/sqlite_memory.db` | ì„¸ì…˜ ìš”ì•½, ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ |
| M4 Long-Term Memory | `memory/permanent/` | `data/chroma_db/` | ì‹œë§¨í‹± ë²¡í„° ê²€ìƒ‰, ì¤‘ìš”ë„ decay |
| M5.1 MemGPT | `memory/memgpt.py` | ì¸ë©”ëª¨ë¦¬ | í† í° ì˜ˆì‚° ì„ íƒ, ì£¼ì œ ë‹¤ì–‘ì„± |
| M5.2 GraphRAG | `memory/graph_rag/` | `data/knowledge_graph.json` | ì—”í‹°í‹°/ê´€ê³„ ê·¸ë˜í”„, BFS íƒìƒ‰ |
| M5.3 MetaMemory | `memory/meta_memory.py` | SQLite | ì ‘ê·¼ ë¹ˆë„, ì±„ë„ ë‹¤ì–‘ì„± |

### ë©”ëª¨ë¦¬ Decay

ë©”ëª¨ë¦¬ëŠ” ì ì‘í˜• ë§ê° ê³¡ì„ ì„ ì‚¬ìš©í•˜ì—¬ ì‹œê°„ì´ ì§€ë‚¨ì— ë”°ë¼ ê°ì†Œí•©ë‹ˆë‹¤:

```
decayed_importance = importance * decay_factor

decay_factor = f(
    time_elapsed,           # ì§€ìˆ˜ì  ì‹œê°„ ê°ì†Œ
    base_rate=0.001,        # MEMORY_BASE_DECAY_RATEë¡œ ì„¤ì •
    access_count,           # ë°˜ë³µ ì ‘ê·¼ ì‹œ decay ë‘”í™”
    connection_count,       # ê·¸ë˜í”„ ì—°ê²°ëœ ë©”ëª¨ë¦¬ëŠ” decay ì €í•­
    memory_type_modifier,   # ì‚¬ì‹¤ì€ ëŒ€í™”ë³´ë‹¤ ì²œì²œíˆ decay
    circadian_stability     # í”¼í¬ ì‹œê°„ëŒ€ ë¶€ìŠ¤íŠ¸ (apply_circadian_stability())
)

ì‚­ì œ ì„ê³„ê°’: 0.03   (MEMORY_DECAY_DELETE_THRESHOLD)
ìµœì†Œ ë³´ì¡´: 0.3      (MEMORY_MIN_RETENTION)
ìœ ì‚¬ë„ ì¤‘ë³µ ì œê±°: 0.90  (MEMORY_SIMILARITY_THRESHOLD)
```

### ê²€ìƒ‰ ìŠ¤ì½”ì–´ë§

ì¥ê¸° ë©”ëª¨ë¦¬ ê²€ìƒ‰ì€ ë‹¤ë‹¨ê³„ ìŠ¤ì½”ì–´ë§ íŒŒì´í”„ë¼ì¸ì„ ì ìš©í•©ë‹ˆë‹¤:

```
effective_score = base_relevance * decay_factor * importance_weight

importance_weight = 0.5 + 0.5 * clamp(importance, 0, 1)   # ë²”ìœ„: [0.5, 1.0]
```

- **M5 Hot Memory ë¶€ìŠ¤íŠ¸**: MetaMemoryê°€ "hot"ìœ¼ë¡œ í‘œì‹œí•œ ë©”ëª¨ë¦¬ì— ìŠ¤ì½”ì–´ ë³´ë„ˆìŠ¤ (+0.1) ì ìš©
- **GraphRAG LLM ê´€ë ¨ì„±**: ë¹„ë™ê¸° ì¿¼ë¦¬ì—ì„œ ì—”í‹°í‹° ìˆ˜ ê¸°ë°˜ ë‹¨ìˆœ ê³„ì‚° ëŒ€ì‹  LLM ê´€ë ¨ì„± í‰ê°€ ì‚¬ìš©

### ì»¨í…ìŠ¤íŠ¸ ì¡°ë¦½

`await MemoryManager.build_smart_context()`ëŠ” ë¬¸ì ì˜ˆì‚° ë‚´ì—ì„œ ëª¨ë“  ê³„ì¸µì˜ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë¹„ë™ê¸° ë³‘ë ¬ë¡œ ì¡°ë¦½í•©ë‹ˆë‹¤ (sync ë˜í¼: `build_smart_context_sync()`):

| ì„¹ì…˜ | ê¸°ë³¸ ì˜ˆì‚° (ë¬¸ì) | ì„¤ì • í‚¤ |
|------|-----------------|---------|
| ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ | 20,000 | `BUDGET_SYSTEM_PROMPT` |
| ì‹œê°„ ì»¨í…ìŠ¤íŠ¸ | 5,000 | `BUDGET_TEMPORAL` |
| ì›Œí‚¹ ë©”ëª¨ë¦¬ | 80,000 | `BUDGET_WORKING_MEMORY` |
| ì¥ê¸° ë©”ëª¨ë¦¬ | 30,000 | `BUDGET_LONG_TERM` |
| GraphRAG | 12,000 | `BUDGET_GRAPHRAG` |
| ì„¸ì…˜ ì•„ì¹´ì´ë¸Œ | 8,000 | `BUDGET_SESSION_ARCHIVE` |

`ContextService`ëŠ” M0(ì´ë²¤íŠ¸ ë²„í¼)ê³¼ M5(Hot ë©”ëª¨ë¦¬) ì„¹ì…˜ë„ ì¡°íšŒí•˜ì—¬ ì™„ì „í•œ 6ê³„ì¸µ ì»¤ë²„ë¦¬ì§€ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

### ì„¸ì…˜ ê´€ë¦¬

- **ìë™ ì„¸ì…˜ íƒ€ì„ì•„ì›ƒ**: 30ë¶„ ë¹„í™œì„± ì‹œ í˜„ì¬ ì„¸ì…˜ì„ ìë™ ì¢…ë£Œí•˜ê³  ìƒˆ ì„¸ì…˜ ì‹œì‘
- **ì•± ì¢…ë£Œ ì‹œ LLM ìš”ì•½**: ì¢…ë£Œ ì‹œ LLM ê¸°ë°˜ ì„¸ì…˜ ìš”ì•½ ì‹œë„ (10ì´ˆ íƒ€ì„ì•„ì›ƒ, ì‹¤íŒ¨ ì‹œ fallback)
- **LLM ì¤‘ìš”ë„ í‰ê°€**: ì„¸ì…˜ ì¢…ë£Œ ì‹œ facts/insightsë¥¼ LLMìœ¼ë¡œ ì¤‘ìš”ë„ í‰ê°€ (fallback: 0.5)
- **ìë™ í”„ë¡œëª¨ì…˜ (M2â†’M3)**: LLM ì¤‘ìš”ë„ â‰¥ 0.6ì¸ ì„¸ì…˜ì€ ìë™ìœ¼ë¡œ `conversation` íƒ€ì… ì¥ê¸° ë©”ëª¨ë¦¬ë¡œ ìŠ¹ê²©
- **ë©”ëª¨ë¦¬ ìŠ¹ê²© ê¸°ì¤€**: importance â‰¥ 0.55 ë˜ëŠ” (repetitions â‰¥ 2 AND importance â‰¥ 0.35)

### ìë™ Consolidation

ì•± ë‚´ì—ì„œ 6ì‹œê°„ë§ˆë‹¤ ìë™ìœ¼ë¡œ `consolidate_memories()` ì‹¤í–‰. ë³„ë„ë¡œ `scripts/memory_gc.py`ë¥¼ cronì— ë“±ë¡í•˜ì—¬ í•´ì‹œ/ì‹œë§¨í‹± ì¤‘ë³µ ì œê±°ë„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

- **ì‚¬ìš©ì í–‰ë™ ë©”íŠ¸ë¦­**: Consolidatorê°€ `collect_behavior_metrics()`ë¡œ ì‹¤ì œ ì‚¬ìš©ì í–‰ë™ ë©”íŠ¸ë¦­ì„ ìˆ˜ì§‘í•˜ì—¬ ì ì‘í˜• decayì— í™œìš©
- **ì¤‘ìš”ë„ ì¬í‰ê°€**: ì˜¤ë˜ëœ ë©”ëª¨ë¦¬(>168ì‹œê°„) ì¤‘ ì ‘ê·¼ íšŸìˆ˜ê°€ ë†’ì€ í•­ëª©ì„ ì£¼ê¸°ì ìœ¼ë¡œ LLM ì¬í‰ê°€ (ë°°ì¹˜ í¬ê¸°: 50)
- **GraphRAG â†’ M3 í”¼ë“œë°±**: ì—”í‹°í‹° ì¶”ì¶œ ì‹œ ê´€ë ¨ ì¥ê¸° ë©”ëª¨ë¦¬ì˜ `connection_count`ë¥¼ ìë™ ì—…ë°ì´íŠ¸

### PostgreSQL ë°±ì—”ë“œ (ì„ íƒ)

`DATABASE_URL` ì„¤ì • ì‹œ SQLite/ChromaDB ëŒ€ì‹  PostgreSQL + pgvector ì‚¬ìš©:

```
backend/memory/pg/
  connection.py            # PgConnectionManager (ì—°ê²° í’€)
  memory_repository.py     # PgMemoryRepository (ChromaDB ëŒ€ì²´)
  graph_repository.py      # PgGraphRepository (JSON ê·¸ë˜í”„ ëŒ€ì²´)
  session_repository.py    # PgSessionRepository (SQLite ëŒ€ì²´)
  meta_repository.py       # PgMetaMemoryRepository
  interaction_logger.py    # PgInteractionLogger
```

í•„ìš”: PostgreSQL 17 + pgvector (`systemctl --user start axnmihn-postgres`)

---

## API ì—”ë“œí¬ì¸íŠ¸

ëª¨ë“  ì—”ë“œí¬ì¸íŠ¸ëŠ” `Authorization: Bearer <token>` ë˜ëŠ” `X-API-Key` í—¤ë” ì¸ì¦ì´ í•„ìš”í•©ë‹ˆë‹¤ (í—¬ìŠ¤/ìƒíƒœ ì—”ë“œí¬ì¸íŠ¸ ì œì™¸).

### í—¬ìŠ¤ & ìƒíƒœ

| ì—”ë“œí¬ì¸íŠ¸ | ë©”ì„œë“œ | ì„¤ëª… |
|-----------|--------|------|
| `/health` | GET | ì „ì²´ í—¬ìŠ¤ì²´í¬ (ë©”ëª¨ë¦¬, LLM, ëª¨ë“ˆ, ì»´í¬ë„ŒíŠ¸ latency) |
| `/health/quick` | GET | ìµœì†Œ ìƒì¡´ í™•ì¸ |
| `/metrics` | GET | Prometheus ë©”íŠ¸ë¦­ìŠ¤ (text format) |
| `/auth/status` | GET | ì¸ì¦ ìƒíƒœ |
| `/llm/providers` | GET | ì‚¬ìš© ê°€ëŠ¥í•œ LLM í”„ë¡œë°”ì´ë” |
| `/models` | GET | ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ |

### ì±„íŒ…

| ì—”ë“œí¬ì¸íŠ¸ | ë©”ì„œë“œ | ì„¤ëª… |
|-----------|--------|------|
| `/v1/chat/completions` | POST | ì±„íŒ… ì™„ì„± (ìŠ¤íŠ¸ë¦¬ë°/ë¹„ìŠ¤íŠ¸ë¦¬ë°, OpenAI í˜¸í™˜) |
| `/v1/models` | GET | ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ |

### WebSocket

| ì—”ë“œí¬ì¸íŠ¸ | í”„ë¡œí† ì½œ | ì„¤ëª… |
|-----------|---------|------|
| `/ws` | WebSocket | ì‹¤ì‹œê°„ ì±„íŒ… (ì¸ì¦, Rate Limiting 30msg/min, Heartbeat) |

### ë©”ëª¨ë¦¬

| ì—”ë“œí¬ì¸íŠ¸ | ë©”ì„œë“œ | ì„¤ëª… |
|-----------|--------|------|
| `/memory/consolidate` | POST | Decay + í˜ë¥´ì†Œë‚˜ ì§„í™” íŠ¸ë¦¬ê±° |
| `/memory/stats` | GET | ë©”ëª¨ë¦¬ ê³„ì¸µ í†µê³„ |
| `/memory/search?query=&limit=` | GET | ì‹œë§¨í‹± ë©”ëª¨ë¦¬ ê²€ìƒ‰ |
| `/memory/sessions` | GET | ìµœê·¼ ì„¸ì…˜ ìš”ì•½ |
| `/memory/session/{session_id}` | GET | ì„¸ì…˜ ìƒì„¸ |
| `/memory/interaction-logs` | GET | ìƒí˜¸ì‘ìš© ë¡œê·¸ |
| `/memory/interaction-stats` | GET | ìƒí˜¸ì‘ìš© í†µê³„ |
| `/session/end` | POST | í˜„ì¬ ì„¸ì…˜ ì¢…ë£Œ |

### ì˜¤ë””ì˜¤

| ì—”ë“œí¬ì¸íŠ¸ | ë©”ì„œë“œ | ì„¤ëª… |
|-----------|--------|------|
| `/v1/audio/transcriptions` | POST | STT (Deepgram Nova-3) |
| `/v1/audio/speech` | POST | TTS í•©ì„± |
| `/v1/audio/voices` | GET | ì‚¬ìš© ê°€ëŠ¥í•œ TTS ìŒì„± ëª©ë¡ |
| `/transcribe` | POST | ì˜¤ë””ì˜¤ íŒŒì¼ íŠ¸ëœìŠ¤í¬ë¦½ì…˜ |
| `/upload` | POST | íŒŒì¼ ì—…ë¡œë“œ |

### MCP

| ì—”ë“œí¬ì¸íŠ¸ | ë©”ì„œë“œ | ì„¤ëª… |
|-----------|--------|------|
| `/mcp/status` | GET | MCP ì„œë²„ ìƒíƒœ |
| `/mcp/manifest` | GET | MCP ë„êµ¬ ë§¤ë‹ˆí˜ìŠ¤íŠ¸ |
| `/mcp/execute` | POST | MCP ë„êµ¬ ì‹¤í–‰ |

### OpenAI í˜¸í™˜

| ì—”ë“œí¬ì¸íŠ¸ | ë©”ì„œë“œ | ì„¤ëª… |
|-----------|--------|------|
| `/v1/models` | GET | ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ |
| `/v1/chat/completions` | POST | ì±„íŒ… ì™„ì„± (ìŠ¤íŠ¸ë¦¬ë°/ë¹„ìŠ¤íŠ¸ë¦¬ë°) |

### ì½”ë“œ íƒìƒ‰

| ì—”ë“œí¬ì¸íŠ¸ | ë©”ì„œë“œ | ì„¤ëª… |
|-----------|--------|------|
| `/code/summary` | GET | ì½”ë“œë² ì´ìŠ¤ ìš”ì•½ |
| `/code/files` | GET | ì½”ë“œ íŒŒì¼ ëª©ë¡ |

---

## MCP ìƒíƒœê³„

SSE ì „ì†¡ì„ í†µí•´ ì œê³µë˜ëŠ” 32ê°œ ë„êµ¬. ì¹´í…Œê³ ë¦¬:

- **System (9):** run_command, search_codebase, search_codebase_regex, read_system_logs, list_available_logs, analyze_log_errors, check_task_status, tool_metrics, system_status
- **Memory (6):** query_axel_memory, add_memory, store_memory, retrieve_context, get_recent_logs, memory_stats
- **File (3):** read_file, list_directory, get_source_code
- **Research (6):** web_search, visit_webpage, deep_research, tavily_search, read_artifact, list_artifacts
- **Home Assistant (6):** hass_control_light, hass_control_device, hass_read_sensor, hass_get_state, hass_list_entities, hass_execute_scene
- **Delegation (2):** delegate_to_opus, google_deep_research

ë„êµ¬ í‘œì‹œ ì—¬ë¶€ëŠ” `MCP_DISABLED_TOOLS` ë° `MCP_DISABLED_CATEGORIES` í™˜ê²½ ë³€ìˆ˜ë¡œ ì„¤ì • ê°€ëŠ¥í•©ë‹ˆë‹¤.

---

## ë„¤ì´í‹°ë¸Œ C++ ëª¨ë“ˆ

C++17 + pybind11 + SIMD (AVX2/NEON)ë¥¼ í†µí•œ ì„±ëŠ¥ í¬ë¦¬í‹°ì»¬ ì—°ì‚°:

```
backend/native/src/
  axnmihn_native.cpp      # pybind11 ë°”ì¸ë”©
  decay.cpp/.hpp           # ë©”ëª¨ë¦¬ decay (SIMD ë°°ì¹˜)
  vector_ops.cpp/.hpp      # ì½”ì‚¬ì¸ ìœ ì‚¬ë„, ì¤‘ë³µ ê°ì§€
  string_ops.cpp/.hpp      # Levenshtein ê±°ë¦¬
  graph_ops.cpp/.hpp       # BFS íƒìƒ‰
  text_ops.cpp/.hpp        # í…ìŠ¤íŠ¸ ì²˜ë¦¬
```

ëª¨ë“ˆì´ ì„¤ì¹˜ë˜ì§€ ì•Šì€ ê²½ìš° ëª¨ë“  í˜¸ì¶œ ì§€ì ì€ ìˆœìˆ˜ Pythonìœ¼ë¡œ í´ë°±ë©ë‹ˆë‹¤.

```bash
cd backend/native && pip install .
# í•„ìš”: CMake 3.18+, C++17 ì»´íŒŒì¼ëŸ¬, pybind11
```

---

## ì„¤ì •

### í™˜ê²½ ë³€ìˆ˜ (`.env`)

```bash
# API Keys
GEMINI_API_KEY=your-gemini-api-key
ANTHROPIC_API_KEY=your-anthropic-api-key
OPENAI_API_KEY=your-openai-api-key
TAVILY_API_KEY=your-tavily-api-key
DEEPGRAM_API_KEY=your-deepgram-api-key

# Home Assistant
HASS_URL=http://homeassistant.local:8123
HASS_TOKEN=your-hass-long-lived-token

# Server
AXNMIHN_API_KEY=your-api-key
HOST=0.0.0.0
PORT=8000
DEBUG=false
TZ=America/Vancouver

# Models
CHAT_PROVIDER=google
GEMINI_MODEL=gemini-3-flash-preview
ANTHROPIC_MODEL=claude-sonnet-4-5-20250929
ANTHROPIC_THINKING_BUDGET=10000
EMBEDDING_MODEL=models/gemini-embedding-001
EMBEDDING_DIMENSION=3072

# Memory budgets (chars)
BUDGET_SYSTEM_PROMPT=20000
BUDGET_TEMPORAL=5000
BUDGET_WORKING_MEMORY=80000
BUDGET_LONG_TERM=30000
BUDGET_GRAPHRAG=12000
BUDGET_SESSION_ARCHIVE=8000

# Memory decay
MEMORY_BASE_DECAY_RATE=0.001
MEMORY_MIN_RETENTION=0.3
MEMORY_DECAY_DELETE_THRESHOLD=0.03
MEMORY_SIMILARITY_THRESHOLD=0.90
MEMORY_MIN_IMPORTANCE=0.55

# Context
CONTEXT_WORKING_TURNS=20
CONTEXT_FULL_TURNS=6
CONTEXT_MAX_CHARS=500000

# Providers
DEFAULT_LLM_PROVIDER=gemini
SEARCH_PROVIDER=tavily

# PostgreSQL
DATABASE_URL=postgresql://axel:password@localhost:5432/axel
PG_POOL_MIN=2
PG_POOL_MAX=10

# Docker Compose (docker-compose.ymlì—ì„œ ì‚¬ìš©, ì„ íƒ)
# POSTGRES_USER=axel
# POSTGRES_PASSWORD=change-me-in-production
# POSTGRES_DB=axel

# TTS Configuration
TTS_SERVICE_URL=http://127.0.0.1:8002
TTS_SYNTHESIS_TIMEOUT=30.0
TTS_FFMPEG_TIMEOUT=10.0
TTS_QUEUE_MAX_PENDING=3
TTS_IDLE_TIMEOUT=300

# Channel Adapters (Discord / Telegram)
DISCORD_BOT_TOKEN=
DISCORD_ALLOWED_CHANNELS=           # comma-separated channel IDs (optional)
TELEGRAM_BOT_TOKEN=
TELEGRAM_ALLOWED_USERS=             # comma-separated usernames (optional)
TELEGRAM_ALLOWED_CHATS=             # comma-separated chat IDs (optional)

# Admin
AXNMIHN_ADMIN_EMAIL=admin@example.com
```

---

## ë¹ ë¥¸ ì‹œì‘

### ì˜µì…˜ A: Systemd ì„œë¹„ìŠ¤

```bash
git clone https://github.com/NorthProt-Inc/axnmihn.git
cd axnmihn

cp .env.example .env
# .env íŒŒì¼ì—ì„œ API í‚¤ ì„¤ì •

# ì¸í”„ë¼ ì„œë¹„ìŠ¤ ì‹œì‘
systemctl --user start axnmihn-postgres axnmihn-redis

# ë°±ì—”ë“œ ì‹œì‘
systemctl --user start axnmihn-backend axnmihn-mcp axnmihn-research

# í™•ì¸
curl http://localhost:8000/health/quick
```

backend (8000) + MCP (8555) + research (8766) + PostgreSQL (5432) + Redis (6379).

### ì˜µì…˜ B: ë¡œì»¬ ê°œë°œ

```bash
git clone https://github.com/NorthProt-Inc/axnmihn.git
cd axnmihn

python3.12 -m venv venv
source venv/bin/activate
pip install -r backend/requirements.txt

cp .env.example .env
# .env íŒŒì¼ì—ì„œ API í‚¤ ì„¤ì •

# (ì„ íƒ) ë„¤ì´í‹°ë¸Œ C++ ëª¨ë“ˆ
cd backend/native && pip install . && cd ../..

# (ì„ íƒ) ë¦¬ì„œì¹˜ìš© Playwright
playwright install chromium

# PostgreSQL + Redis (systemd ì„œë¹„ìŠ¤)
systemctl --user start axnmihn-postgres axnmihn-redis

# ì‹¤í–‰
uvicorn backend.app:app --host 0.0.0.0 --port 8000
curl http://localhost:8000/health
```

---

## ë°°í¬

### Systemd ì„œë¹„ìŠ¤ (ê¸°ë³¸)

| ì„œë¹„ìŠ¤ | í¬íŠ¸ | ëª©ì  | ë¦¬ì†ŒìŠ¤ |
|--------|------|------|--------|
| `axnmihn-backend` | 8000 | FastAPI ë°±ì—”ë“œ | 4G RAM, 200% CPU |
| `axnmihn-mcp` | 8555 | MCP ì„œë²„ (SSE) | 1G RAM, 100% CPU |
| `axnmihn-research` | 8766 | Research MCP | 2G RAM, 150% CPU |
| `axnmihn-tts` | 8002 | TTS ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ (Qwen3-TTS) | 4G RAM, 200% CPU |
| `axnmihn-wakeword` | - | Wakeword ê°ì§€ | 512M RAM, 50% CPU |
| `context7-mcp` | 3002 | Context7 MCP | 1G RAM |
| `markitdown-mcp` | 3001 | Markitdown MCP | 1G RAM |

ìì„¸í•œ ìš´ì˜ ê°€ì´ë“œëŠ” [OPERATIONS.md](OPERATIONS.md) ì°¸ì¡°.

### Docker Compose (ì„ íƒ)

ì•± ì„œë¹„ìŠ¤ì˜ Docker ë°°í¬ë„ ì§€ì›í•œë‹¤. ì¸í”„ë¼(PostgreSQL, Redis)ëŠ” systemdë¡œ ìš´ì˜í•˜ê³ , ì•±ë§Œ Dockerë¡œ ì‹¤í–‰í•˜ëŠ” í•˜ì´ë¸Œë¦¬ë“œ êµ¬ì„±ì´ ê°€ëŠ¥í•˜ë‹¤.

```bash
docker compose up -d              # ì•± ì„œë¹„ìŠ¤ ì‹œì‘
docker compose ps                 # ìƒíƒœ
docker compose logs backend -f    # ë°±ì—”ë“œ ë¡œê·¸
docker compose down               # ì¤‘ì§€
```

| ì„œë¹„ìŠ¤ | í¬íŠ¸ | ì´ë¯¸ì§€/íƒ€ê²Ÿ | ë¦¬ì†ŒìŠ¤ |
|--------|------|------------|--------|
| `backend` | 8000 | Dockerfile -> runtime | 4G RAM, 2 CPU |
| `mcp` | 8555 | Dockerfile -> runtime | 1G RAM, 1 CPU |
| `research` | 8766 | Dockerfile -> research | 2G RAM, 1.5 CPU |

### ìœ ì§€ë³´ìˆ˜

| ìŠ¤í¬ë¦½íŠ¸ | ëª©ì  |
|---------|------|
| `scripts/memory_gc.py` | ë©”ëª¨ë¦¬ ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ (ì¤‘ë³µ ì œê±°, decay, ì´ˆê³¼ í¬ê¸° ì œê±°) |
| `scripts/db_maintenance.py` | SQLite VACUUM, ANALYZE, ë¬´ê²°ì„± ì²´í¬ |
| `scripts/dedup_knowledge_graph.py` | ì§€ì‹ ê·¸ë˜í”„ ì¤‘ë³µ ì œê±° |
| `scripts/regenerate_persona.py` | 7ì¼ ì¦ë¶„ í˜ë¥´ì†Œë‚˜ ì—…ë°ì´íŠ¸ |
| `scripts/optimize_memory.py` | 4ë‹¨ê³„ ë©”ëª¨ë¦¬ ìµœì í™” (í…ìŠ¤íŠ¸ ì •ë¦¬, ì—­í•  ì •ê·œí™”) |
| `scripts/cleanup_messages.py` | LLM ê¸°ë°˜ ë©”ì‹œì§€ ì •ë¦¬ (ë³‘ë ¬, ì²´í¬í¬ì¸íŠ¸) |
| `scripts/populate_knowledge_graph.py` | ì§€ì‹ ê·¸ë˜í”„ ì´ˆê¸° ì±„ìš°ê¸° |
| `scripts/night_ops.py` | ìë™í™”ëœ ì•¼ê°„ ë¦¬ì„œì¹˜ |
| `scripts/run_migrations.py` | ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ë§ˆì´ê·¸ë ˆì´ì…˜ |

---

## í”„ë¡œì íŠ¸ êµ¬ì¡°

```
axnmihn/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app.py                    # FastAPI ì§„ì…ì , ë¼ì´í”„ìŠ¤íŒ¬
â”‚   â”œâ”€â”€ config.py                 # ëª¨ë“  ì„¤ì •
â”‚   â”œâ”€â”€ api/                      # HTTP ë¼ìš°í„° (status, chat, memory, mcp, media, audio, openai)
â”‚   â”œâ”€â”€ core/                     # í•µì‹¬ ì„œë¹„ìŠ¤
â”‚   â”‚   â”œâ”€â”€ chat_handler.py       # ë©”ì‹œì§€ ë¼ìš°íŒ…
â”‚   â”‚   â”œâ”€â”€ context_optimizer.py  # ì»¨í…ìŠ¤íŠ¸ í¬ê¸° ê´€ë¦¬
â”‚   â”‚   â”œâ”€â”€ mcp_client.py        # MCP í´ë¼ì´ì–¸íŠ¸
â”‚   â”‚   â”œâ”€â”€ mcp_server.py        # MCP ì„œë²„ ì„¤ì •
â”‚   â”‚   â”œâ”€â”€ health/              # í—¬ìŠ¤ ëª¨ë‹ˆí„°ë§
â”‚   â”‚   â”œâ”€â”€ identity/            # AI í˜ë¥´ì†Œë‚˜ (ai_brain.py)
â”‚   â”‚   â”œâ”€â”€ intent/              # ì˜ë„ ë¶„ë¥˜
â”‚   â”‚   â”œâ”€â”€ logging/             # êµ¬ì¡°í™”ëœ ë¡œê¹…
â”‚   â”‚   â”œâ”€â”€ mcp_tools/           # ë„êµ¬ êµ¬í˜„
â”‚   â”‚   â”œâ”€â”€ persona/             # ì±„ë„ ì ì‘
â”‚   â”‚   â”œâ”€â”€ security/            # í”„ë¡¬í”„íŠ¸ ë°©ì–´
â”‚   â”‚   â”œâ”€â”€ session/             # ì„¸ì…˜ ìƒíƒœ
â”‚   â”‚   â”œâ”€â”€ telemetry/           # ìƒí˜¸ì‘ìš© ë¡œê¹…
â”‚   â”‚   â””â”€â”€ utils/               # ìºì‹œ, ì¬ì‹œë„, HTTP í’€, Gemini í´ë¼ì´ì–¸íŠ¸, circuit breaker
â”‚   â”œâ”€â”€ llm/                     # LLM í”„ë¡œë°”ì´ë” (Gemini, Anthropic)
â”‚   â”œâ”€â”€ media/                   # TTS ê´€ë¦¬ì
â”‚   â”œâ”€â”€ memory/                  # 6ê³„ì¸µ ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ
â”‚   â”‚   â”œâ”€â”€ unified/             # MemoryManager ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° (core, facade, context_builder, session)
â”‚   â”‚   â”œâ”€â”€ event_buffer.py      # M0: ì´ë²¤íŠ¸ ë²„í¼
â”‚   â”‚   â”œâ”€â”€ current.py           # M1: ì›Œí‚¹ ë©”ëª¨ë¦¬
â”‚   â”‚   â”œâ”€â”€ recent/              # M3: ì„¸ì…˜ ì•„ì¹´ì´ë¸Œ (SQLite)
â”‚   â”‚   â”œâ”€â”€ permanent/           # M4: ì¥ê¸° (ChromaDB)
â”‚   â”‚   â”œâ”€â”€ memgpt.py            # M5.1: ì˜ˆì‚° ì„ íƒ
â”‚   â”‚   â”œâ”€â”€ graph_rag/            # M5.2: ì§€ì‹ ê·¸ë˜í”„
â”‚   â”‚   â”œâ”€â”€ meta_memory.py       # M5.3: ì ‘ê·¼ ì¶”ì 
â”‚   â”‚   â”œâ”€â”€ temporal.py          # ì‹œê°„ ì»¨í…ìŠ¤íŠ¸
â”‚   â”‚   â””â”€â”€ pg/                  # PostgreSQL ë°±ì—”ë“œ (ì„ íƒ)
â”‚   â”œâ”€â”€ native/                  # C++17 í™•ì¥ ëª¨ë“ˆ
â”‚   â”œâ”€â”€ channels/                # ì±„ë„ ì–´ëŒ‘í„° ì‹œìŠ¤í…œ
â”‚   â”‚   â”œâ”€â”€ protocol.py          # ChannelAdapter Protocol
â”‚   â”‚   â”œâ”€â”€ manager.py           # ë¼ì´í”„ì‚¬ì´í´ ê´€ë¦¬
â”‚   â”‚   â”œâ”€â”€ message_chunker.py   # í”Œë«í¼ë³„ ë©”ì‹œì§€ ë¶„í• 
â”‚   â”‚   â”œâ”€â”€ bridge.py            # ChatHandler ë¸Œë¦¿ì§€
â”‚   â”‚   â”œâ”€â”€ discord/bot.py       # Discord ì–´ëŒ‘í„°
â”‚   â”‚   â”œâ”€â”€ telegram/bot.py      # Telegram ì–´ëŒ‘í„°
â”‚   â”‚   â””â”€â”€ commands/registry.py # ì¸ë¼ì¸ ì»¤ë§¨ë“œ íŒŒì„œ
â”‚   â”œâ”€â”€ protocols/mcp/           # MCP í”„ë¡œí† ì½œ í•¸ë“¤ëŸ¬
â”‚   â””â”€â”€ wake/                    # Wakeword + ìŒì„± ëŒ€í™”
â”œâ”€â”€ tests/                       # pytest í…ŒìŠ¤íŠ¸ ìŠ¤ìœ„íŠ¸
â”œâ”€â”€ scripts/                     # ìë™í™” ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ data/                        # ëŸ°íƒ€ì„ ë°ì´í„° (SQLite, ChromaDB, JSON)
â”œâ”€â”€ logs/                        # ì• í”Œë¦¬ì¼€ì´ì…˜ ë¡œê·¸
â”œâ”€â”€ storage/                     # ë¦¬ì„œì¹˜ ì•„í‹°íŒ©íŠ¸, í¬ë¡  ë³´ê³ ì„œ
â”œâ”€â”€ Dockerfile                   # ë©€í‹°ìŠ¤í…Œì´ì§€ (runtime + research)
â”œâ”€â”€ docker-compose.yml           # ì „ì²´ ìŠ¤íƒ (app + PG + Redis)
â”œâ”€â”€ .dockerignore
â”œâ”€â”€ pyproject.toml               # í”„ë¡œì íŠ¸ ë©”íƒ€ë°ì´í„°
â””â”€â”€ .env                         # í™˜ê²½ ì„¤ì •
```

---

## ë¬¸ì„œ

- [OPERATIONS.md](OPERATIONS.md) â€” ìš´ì˜ ê°€ì´ë“œ (í•œ/ì˜)
- [AGENTS.md](AGENTS.md) â€” ì»¤ìŠ¤í…€ ì—ì´ì „íŠ¸ ì •ì˜
- [logging.md](logging.md) â€” ë¡œê¹… ì‹œìŠ¤í…œ ë¬¸ì„œ
- [memory-system-analysis.md](memory-system-analysis.md) â€” ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ ë¶„ì„ ë³´ê³ ì„œ
- [backend/native/README.md](backend/native/README.md) â€” C++ ë„¤ì´í‹°ë¸Œ ëª¨ë“ˆ
- `.github/instructions/` â€” ê°œë°œ ì§€ì¹¨ (TDD, ë³´ì•ˆ, ì„±ëŠ¥, ì—ëŸ¬ ë¶„ì„)

---

## ê¸°ì—¬

1. Fork the repository
2. Create feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'feat: add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open Pull Request

**ì»¤ë°‹ ê·œì¹™:** Conventional Commits (`feat:`, `fix:`, `docs:`, `refactor:`, etc.)

**ì½”ë“œ ìŠ¤íƒ€ì¼:**
- Python: `black` í¬ë§¤íŒ…, `ruff` ë¦°íŠ¸, type hints í•„ìˆ˜
- í•¨ìˆ˜ ìµœëŒ€ 400ì¤„, íŒŒì¼ ìµœëŒ€ 800ì¤„
- Protocol ê¸°ë°˜ ì¸í„°í˜ì´ìŠ¤, dataclass/pydantic ë°ì´í„°
- async def ìš°ì„  (I/O-bound ì‘ì—…)

---

## ë¼ì´ì„ ìŠ¤

MIT License - ìì„¸í•œ ë‚´ìš©ì€ [LICENSE](LICENSE) ì°¸ì¡°

---

## ê°ì‚¬ì˜ ë§

- **FastAPI** â€” í˜„ëŒ€ì ì¸ ì›¹ í”„ë ˆì„ì›Œí¬
- **ChromaDB** â€” ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤
- **Anthropic & Google** â€” LLM API
- **Deepgram** â€” ìŒì„± ì¸ì‹
- **Model Context Protocol** â€” ë„êµ¬ í†µí•© í‘œì¤€

---

**ì œì‘:** NorthProt Inc.  
**ë¬¸ì˜:** [GitHub Issues](https://github.com/NorthProt-Inc/axnmihn/issues)

</details>
