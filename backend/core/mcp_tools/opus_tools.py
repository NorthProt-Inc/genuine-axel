from typing import Any, Sequence
from mcp.types import TextContent
from . import register_tool
from backend.core.logging.logging import get_logger

_log = get_logger("mcp.opus_tools")

@register_tool(
    "delegate_to_opus",
    category="delegation",
    description="""ðŸ Claude Opusì—ê²Œ ì½”ë”© ìž‘ì—… ìœ„ìž„ (Silent Intern).

[í•„ìˆ˜ ì‚¬ìš© ì¡°ê±´] ì‚¬ìš©ìžê°€ ë‹¤ìŒ í‚¤ì›Œë“œ ì–¸ê¸‰ ì‹œ ë°˜ë“œì‹œ ì´ ë„êµ¬ í˜¸ì¶œ:
- "Opusí•œí…Œ ì‹œì¼œ", "Opus ë¶ˆëŸ¬", "Silent Intern"
- "ì½”ë“œ ì§œì¤˜", "ë¦¬íŒ©í† ë§ í•´ì¤˜", "íŒŒì¼ ìˆ˜ì •í•´ì¤˜"
- "delegate_to_opus" (ë„êµ¬ ì´ë¦„ ì§ì ‘ ì–¸ê¸‰)

[ìš©ë„]
- ë³µìž¡í•œ ì½”ë“œ ìƒì„±/ë¦¬íŒ©í† ë§
- ì—¬ëŸ¬ íŒŒì¼ ë™ì‹œ ìˆ˜ì •
- í…ŒìŠ¤íŠ¸ ì½”ë“œ ìž‘ì„±
- ì½”ë“œë² ì´ìŠ¤ ë¶„ì„

[ì‚¬ìš©ë²•]
instruction: ìž‘ì—… ì§€ì‹œì‚¬í•­ (êµ¬ì²´ì ìœ¼ë¡œ)
file_paths: ê´€ë ¨ íŒŒì¼ ê²½ë¡œ (ì‰¼í‘œ êµ¬ë¶„)

âš ï¸ ì´ ë„êµ¬ëŠ” ì‹¤ì œë¡œ Opus APIë¥¼ í˜¸ì¶œí•¨. ë§ë¡œë§Œ "ì‹œí‚¨ë‹¤" í•˜ì§€ ë§ê³  ë°˜ë“œì‹œ function_call ìƒì„±í•  ê²ƒ.""",
    input_schema={
        "type": "object",
        "properties": {
            "instruction": {
                "type": "string",
                "description": "Clear, detailed instruction for the coding task"
            },
            "file_paths": {
                "type": "string",
                "description": "Comma-separated file paths (e.g., 'core/main.py,core/utils.py')"
            },
            "model": {
                "type": "string",
                "enum": ["opus", "sonnet", "haiku"],
                "description": "Model to use: opus=best quality, sonnet=balanced, haiku=fast",
                "default": "opus"
            }
        },
        "required": ["instruction"]
    }
)
async def delegate_to_opus_tool(arguments: dict[str, Any]) -> Sequence[TextContent]:
    """Delegate a coding task to Claude Opus via Silent Intern.

    Args:
        arguments: Dict with instruction, file_paths, and model

    Returns:
        TextContent with execution result or error
    """
    instruction = arguments.get("instruction", "")
    file_paths_raw = arguments.get("file_paths", "")
    model = arguments.get("model", "opus")
    _log.debug("TOOL invoke", fn="delegate_to_opus", model=model, instruction_len=len(instruction) if instruction else 0)

    if not instruction:
        _log.warning("TOOL fail", fn="delegate_to_opus", err="instruction parameter required")
        return [TextContent(type="text", text="Error: instruction parameter is required")]

    if model not in ["opus", "sonnet", "haiku"]:
        _log.warning("TOOL fail", fn="delegate_to_opus", err="invalid model")
        return [TextContent(type="text", text="Error: model must be 'opus', 'sonnet', or 'haiku'")]

    file_paths = [p.strip() for p in file_paths_raw.split(",") if p.strip()] if file_paths_raw else []

    try:
        from backend.core.tools.opus_executor import _generate_task_summary
        task_summary = _generate_task_summary(instruction)
    except ImportError:
        task_summary = instruction[:50] + "..." if len(instruction) > 50 else instruction

    try:
        from backend.core.tools.opus_executor import delegate_to_opus

        result = await delegate_to_opus(
            instruction=instruction,
            file_paths=file_paths,
            model=model
        )

        if result.success:
            _log.info("TOOL ok", fn="delegate_to_opus", model=model, time_s=result.execution_time, files=len(result.files_included))

            output_parts = ["Opus Task Completed", ""]
            if result.files_included:
                output_parts.append(f"**Context Files:** {', '.join(result.files_included)}")
            output_parts.append(f"**Execution Time:** {result.execution_time:.2f}s")
            output_parts.append("")
            output_parts.append("## Response")
            output_parts.append(result.response)
            return [TextContent(type="text", text="\n".join(output_parts))]
        else:
            _log.warning("TOOL partial", fn="delegate_to_opus", model=model, err=result.error[:100] if result.error else None)
            return [TextContent(type="text", text=f"Opus Error: {result.error}\n\n{result.response}")]

    except Exception as e:
        _log.error("TOOL fail", fn="delegate_to_opus", err=str(e)[:100])
        return [TextContent(type="text", text=f"Opus Error: {str(e)}")]

@register_tool(
    "google_deep_research",
    category="delegation",
    description="""ðŸ”¬ Google Deep Research Agent (Gemini Interactions API).

[í•„ìˆ˜ ì‚¬ìš© ì¡°ê±´] ì‚¬ìš©ìžê°€ ë‹¤ìŒ í‚¤ì›Œë“œ ì–¸ê¸‰ ì‹œ ë°˜ë“œì‹œ ì´ ë„êµ¬ í˜¸ì¶œ:
- "êµ¬ê¸€ ë¦¬ì„œì¹˜", "Google ë¦¬ì„œì¹˜", "Gemini ë¦¬ì„œì¹˜"
- "êµ¬ê¸€ ë”¥ë¦¬ì„œì¹˜", "google_deep_research" (ë„êµ¬ ì´ë¦„ ì§ì ‘ ì–¸ê¸‰)

[ìš©ë„]
- ìµœì‹  ë…¼ë¬¸/ê¸°ìˆ  íŠ¸ë Œë“œ ì‹¬ì¸µ ë¶„ì„
- ë³µìž¡í•œ ë¹„êµ ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±
- 2025-2026ë…„ ìµœì‹  ì •ë³´ ì¡°ì‚¬

[íŠ¹ì§•]
- ë¹„ë™ê¸° ëª¨ë“œ (ê¸°ë³¸ê°’) - ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰ í›„ ì¦‰ì‹œ ì‘ë‹µ
- Intern ë¶„ì„ ìžë™ ìˆ˜í–‰ (Gemini Proë¡œ ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ)
- ê²°ê³¼ë¬¼: storage/research/inbox/*.md ì €ìž¥
- Gemini API í‚¤ ë¡œí…Œì´ì…˜ (3ê°œ í‚¤ ìˆœí™˜)

[íŒŒë¼ë¯¸í„°]
- query: ê²€ìƒ‰ì–´ (í•„ìˆ˜)
- depth: 1-5 (ê¹Šì´, ê¸°ë³¸ 3)
- async_mode: true(ê¸°ë³¸)/false - ë¹„ë™ê¸° ì‹¤í–‰ ì—¬ë¶€

ì¼ë°˜ ì›¹ ê²€ìƒ‰ì€ deep_research(ë¬´ë£Œ) ì‚¬ìš©.""",
    input_schema={
        "type": "object",
        "properties": {
            "query": {
                "type": "string",
                "description": "Research query - be specific and detailed for best results"
            },
            "depth": {
                "type": "integer",
                "description": "Research depth 1-5 (optional, default: 3). Higher = more thorough analysis.",
                "minimum": 1,
                "maximum": 5,
                "default": 3
            },
            "async_mode": {
                "type": "boolean",
                "description": "Run in background (default: true). Set false to wait for results.",
                "default": True
            }
        },
        "required": ["query"]
    }
)
async def google_deep_research_tool(arguments: dict[str, Any]) -> Sequence[TextContent]:
    """Execute deep research using Google Gemini Interactions API.

    Args:
        arguments: Dict with query, depth, and async_mode

    Returns:
        TextContent with research results or async task confirmation
    """
    query = arguments.get("query", "")
    depth = arguments.get("depth", 3)
    async_mode = arguments.get("async_mode", True)
    _log.debug("TOOL invoke", fn="google_deep_research", query=query[:50] if query else None, depth=depth, async_mode=async_mode)

    if not query:
        _log.warning("TOOL fail", fn="google_deep_research", err="query parameter required")
        return [TextContent(type="text", text="Error: query parameter is required")]

    if depth is not None:
        if not isinstance(depth, int) or depth < 1 or depth > 5:
            _log.warning("TOOL fail", fn="google_deep_research", err="invalid depth")
            return [TextContent(type="text", text="Error: depth must be between 1 and 5")]

    try:
        if async_mode:
            from backend.protocols.mcp.async_research import dispatch_async_research
            result = dispatch_async_research(query, "google", depth)
            _log.info("TOOL ok", fn="google_deep_research", mode="async", res_len=len(result))
            return [TextContent(type="text", text=result)]
        else:
            from backend.protocols.mcp.async_research import run_research_sync
            result = await run_research_sync(query, "google", depth)
            _log.info("TOOL ok", fn="google_deep_research", mode="sync", res_len=len(result))
            return [TextContent(type="text", text=result)]

    except Exception as e:
        _log.error("TOOL fail", fn="google_deep_research", err=str(e)[:100])
        return [TextContent(type="text", text=f"âœ— Google Research Error: {str(e)}")]
